{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2154564/imagination/blob/main/Imagination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPkOzujWZyWQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flvcR_YLyPAX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install flask_ngrok\n",
        "!pip install pyngrok==4.1.1\n",
        "!pip install Werkzeug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qb1gUpXZatwL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run(instance_prompt,class_prompt,training_steps):\n",
        "\n",
        "  HUGGINGFACE_TOKEN = \"\"\n",
        "\n",
        "  #markdown Name/Path of the initial model.\n",
        "  MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "  BRANCH = \"fp16\"\n",
        "\n",
        "\n",
        "#markdown Enter instance prompt and class prompt.\\\n",
        "#markdown Example 1: photo of zwx person, photo of a person\\\n",
        "#markdown Example 2: photo of zwx toy, photo of a toy\n",
        "  learning_rate = 1e-6 #param {type:\"number\"}\n",
        "  output_file = \"AI_PICS/models/my_dreambooth_model.safetensors\" #param {type:\"string\"}\n",
        "#markdown  Convert to fp16? (takes half the space (2GB)).\n",
        "  fp16 = True #param {type: \"boolean\"}\n",
        "\n",
        "#markdown Clear log after run?\n",
        "  CLEAR_LOG = False #param {type:\"boolean\"}\n",
        "\n",
        "# Mount google drive for saving the model\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  OUTPUT_DIR = \"/content/drive/MyDrive/output/output\"\n",
        "  INSTANCE_DIR = \"/content/drive/MyDrive/data/instance\"\n",
        "  CLASS_DIR = \"/content/drive/MyDrive/data/class\"\n",
        "\n",
        "  !mkdir -p $INSTANCE_DIR\n",
        "  !mkdir -p $CLASS_DIR\n",
        "\n",
        "  !rm -rf $OUTPUT_DIR\n",
        "  !mkdir -p $OUTPUT_DIR\n",
        "\n",
        "  if 'pipe' in locals():\n",
        "    del pipe\n",
        "\n",
        "# Check type of GPU and VRAM available.\n",
        "  # !nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "  !nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "\n",
        "# Upload training images.\n",
        "  import os\n",
        "  from google.colab import files\n",
        "  import shutil\n",
        "\n",
        "\n",
        "  time_start = time.time()\n",
        "  def clear():\n",
        "      from IPython.display import clear_output; return clear_output()\n",
        "\n",
        "# huggingface token\n",
        "  !mkdir -p ~/.huggingface\n",
        "  !echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "\n",
        "# install diffusers\n",
        "  !git clone https://github.com/sagiodev/diffusers.git #https://github.com/huggingface/diffusers.git\n",
        "  %cd diffusers\n",
        "  !git checkout 08b453e3828f80027d881bb460716af95e192bcd -- ./scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "  %pip install .\n",
        "\n",
        "\n",
        "# install dreambooth\n",
        "  %cd /content/diffusers/examples/dreambooth\n",
        "  %pip install -r requirements.txt\n",
        "  %pip install bitsandbytes #xformers torch==2.1.0+cu121 # gradio natsort safetensors xformers torch==2.1.0+cu121 accelerate\n",
        "  !accelerate config default\n",
        "\n",
        "\n",
        "# test bitsandbytes\n",
        "  import bitsandbytes\n",
        "  import torch\n",
        "  print(torch.__version__)\n",
        "\n",
        "# Dreambooth training - Edit this section to customize parameters\n",
        "  !accelerate launch train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "    --revision=$BRANCH \\\n",
        "    --instance_prompt=\"$instance_prompt\" \\\n",
        "    --class_prompt=\"$class_prompt\" \\\n",
        "    --class_data_dir=$CLASS_DIR \\\n",
        "    --instance_data_dir=$INSTANCE_DIR \\\n",
        "    --output_dir=$OUTPUT_DIR \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=$learning_rate \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --num_class_images=50 \\\n",
        "    --sample_batch_size=4 \\\n",
        "    --max_train_steps=$training_steps\n",
        "\n",
        "#  --enable_xformers_memory_efficient_attention \\\n",
        "\n",
        "########################################\n",
        "#prompt = \"photo of zwx\"\n",
        "  prompt = instance_prompt\n",
        "  negative_prompt = \"\"\n",
        "  num_samples = 4\n",
        "  guidance_scale = 7.5\n",
        "  num_inference_steps = 25\n",
        "  height = 512\n",
        "  width = 512\n",
        "  seed = 100\n",
        "\n",
        "  %cd /content/\n",
        "  from diffusers import StableDiffusionPipeline,EulerDiscreteScheduler\n",
        "  from matplotlib.pyplot import figure, imshow, axis\n",
        "  from matplotlib.image import imread\n",
        "  import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "  if 'pipe' not in locals():\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(OUTPUT_DIR, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    g_cuda = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "  g_cuda.manual_seed(seed)\n",
        "\n",
        "  from torch import autocast\n",
        "  with autocast(\"cuda\"), torch.inference_mode():\n",
        "      images = pipe(\n",
        "          prompt,\n",
        "          height=height,\n",
        "          width=width,\n",
        "          negative_prompt=negative_prompt,\n",
        "          num_images_per_prompt=num_samples,\n",
        "          num_inference_steps=num_inference_steps,\n",
        "          guidance_scale=guidance_scale,\n",
        "          generator=g_cuda\n",
        "      ).images\n",
        "\n",
        "      fig=figure(figsize=(5*num_samples,5*num_samples))\n",
        "      for i in range(num_samples):\n",
        "          a=fig.add_subplot(1, num_samples,i+1)\n",
        "          imshow(images[i])\n",
        "          axis('off')\n",
        "\n",
        "\n",
        "######################################\n",
        "# Save to checkpoint file\n",
        "  ckpt_path = '/content/drive/MyDrive/Data_File' + output_file\n",
        "# save model file. Save to a new name if already exist.\n",
        "  dirname= os.path.dirname(ckpt_path)\n",
        "  !mkdir -p $dirname\n",
        "  filename = os.path.basename(ckpt_path)\n",
        "  fileanmeWithoutExt = os.path.splitext(filename)[0]\n",
        "  ExtName = os.path.splitext(filename)[1]\n",
        "  filenamePattern = fileanmeWithoutExt + '%d' + ExtName\n",
        "  i = 1\n",
        "  while os.path.isfile(ckpt_path):\n",
        "    filename = filenamePattern%i\n",
        "    ckpt_path = dirname + '/' + filename\n",
        "    i += 1\n",
        "\n",
        "  half_arg = \"--half\" if fp16 else \"\"\n",
        "  !python /content/diffusers/scripts/convert_diffusers_to_original_stable_diffusion.py \\\n",
        "      --use_safetensors \\\n",
        "      --model_path $OUTPUT_DIR \\\n",
        "      --checkpoint_path $ckpt_path $half_arg\n",
        "  print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "  minutes = (time.time()-time_start)/60\n",
        "  print(\"Dreambooth completed successfully. It took %1.1f minutes.\"%minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1fxoejVpS-Nq"
      },
      "outputs": [],
      "source": [
        "#@title Test image generation from model\n",
        "def run2(prompt,negative_prompt,num_samples ,\n",
        "  guidance_scale ,\n",
        "  height ,\n",
        "  width ):\n",
        "  # install diffusers\n",
        "  !git clone https://github.com/sagiodev/diffusers.git #https://github.com/huggingface/diffusers.git\n",
        "  %cd diffusers\n",
        "  !git checkout 08b453e3828f80027d881bb460716af95e192bcd -- ./scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "  %pip install .\n",
        "\n",
        "\n",
        "# install dreambooth\n",
        "  %cd /content/diffusers/examples/dreambooth\n",
        "  %pip install -r requirements.txt\n",
        "  %pip install bitsandbytes #xformers torch==2.1.0+cu121 # gradio natsort safetensors xformers torch==2.1.0+cu121 accelerate\n",
        "  !accelerate config default\n",
        "\n",
        "  import bitsandbytes\n",
        "  import torch\n",
        "  seed = -1\n",
        "  num_inference_steps = 50\n",
        "\n",
        "  %cd /content/\n",
        "  from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "  from matplotlib.pyplot import figure, imshow, axis\n",
        "  from matplotlib.image import imread\n",
        "  import numpy as np\n",
        "  OUTPUT_DIR = \"/content/drive/MyDrive/output/output\"\n",
        "  INSTANCE_DIR = \"/content/drive/MyDrive/data/instance\"\n",
        "  CLASS_DIR = \"/content/drive/MyDrive/data/class\"\n",
        "  if 'pipe' not in locals():\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(OUTPUT_DIR, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    g_cuda = None\n",
        "\n",
        "\n",
        "\n",
        "  g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "  g_cuda.manual_seed(seed)\n",
        "\n",
        "  from torch import autocast\n",
        "  with autocast(\"cuda\"), torch.inference_mode():\n",
        "      images = pipe(\n",
        "          prompt,\n",
        "          height=height,\n",
        "          width=width,\n",
        "          negative_prompt=negative_prompt,\n",
        "          num_images_per_prompt=num_samples,\n",
        "          num_inference_steps=num_inference_steps,\n",
        "          guidance_scale=guidance_scale,\n",
        "          generator=g_cuda\n",
        "      ).images\n",
        "      output_directory = \"/content/drive/MyDrive/Colab Notebooks/FYP/static\"\n",
        "      i=1\n",
        "      for im in images:\n",
        "        filename = \"generated_image_\"+str(i)+\".png\"\n",
        "        print(filename)\n",
        "        filepath = os.path.join(output_directory, filename)\n",
        "        # Save the image\n",
        "        im.save(filepath)\n",
        "        i=i+1\n",
        "        print()\n",
        "\n",
        "    # Optionally, display the saved filepath\n",
        "      print(f\"Image saved to: {filepath}\")\n",
        "      from ipywidgets import widgets, HBox\n",
        "      from IPython.display import display\n",
        "      for im in images:\n",
        "          display(im)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_uVBs0c3h0A"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGHlyxwNUf0-"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken 2dEysJgwtjumyUuhWZxkmMwuCU6_2nEaorudYLXqoRzYHonjt\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from flask import Flask, render_template, request, redirect, url_for,g , jsonify\n",
        "import sqlite3\n",
        "from flask_ngrok import run_with_ngrok as r\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from werkzeug.utils import secure_filename\n",
        "import os\n",
        "import threading\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pyngrok import ngrok\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "page1=\"yes\"\n",
        "db_path = '/content/drive/MyDrive/Colab Notebooks/FYP/imagination.db'\n",
        "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
        "cursor = conn.cursor()\n",
        "# Check if the table already exists\n",
        "\n",
        "conn.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS `Prompts For Model Training` (\n",
        "        `Instance Prompt` STRING NOT NULL,\n",
        "        `Class Prompt` STRING NOT NULL,\n",
        "        `Training Steps` INTEGER NOT NULL\n",
        "    );\n",
        "''')\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS `Image Generation Prompts` (\n",
        "       `Prompt` STRING NOT NULL,\n",
        "        `Negative Prompt` STRING ,\n",
        "        `Sample Size` INTEGER NOT NULL,\n",
        "        `Guidance Scale` FLOAT NOT NULL\n",
        "    );\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "def get_db():\n",
        "    if 'db' not in g:\n",
        "        g.db = conn\n",
        "    return g.db\n",
        "# Function to close the SQLite connection\n",
        "def close_db(e=None):\n",
        "    pass  # Do nothing, as the connection is shared\n",
        "# Register close_db function to be called when the app context ends\n",
        "# app.teardown_appcontext(close_db)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Specify the path of the folder you want to create\n",
        "folder_path = '/content/drive/MyDrive/data/instance'\n",
        "\n",
        "# Check if the folder already exists\n",
        "if not os.path.exists(folder_path):\n",
        "    # If not, create the folder\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Folder '{folder_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_path}' already exists.\")\n",
        "\n",
        "templates_folder = '/content/drive/MyDrive/Colab Notebooks/FYP/templates'\n",
        "static_folder = '/content/drive/MyDrive/Colab Notebooks/FYP/static'\n",
        "app = Flask(__name__,template_folder = templates_folder,static_folder = static_folder)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "status1 = {'status': 'in_progress'}\n",
        "\n",
        "\n",
        "\n",
        "def process_request1(iprompt,cprompt,steps):\n",
        "    with app.app_context():\n",
        "        try:\n",
        "            global page1\n",
        "            run(iprompt,cprompt,steps)\n",
        "            page1=\"yes\"\n",
        "            status1['status'] = 'completed'\n",
        "            return jsonify(status1)\n",
        "        except Exception as e:\n",
        "            status1['status'] = 'error'\n",
        "            error_message = f\"An error occurred: {str(e)}\"\n",
        "            return jsonify({'status': 'error', 'message': error_message})\n",
        "i=0\n",
        "@app.route('/check_status', methods=['POST'])\n",
        "def check_status1():\n",
        "    global i\n",
        "    print(1)\n",
        "    if i==0:\n",
        "        L=add_numbers()\n",
        "        iprompt=L[0]\n",
        "        cprompt=L[1]\n",
        "        steps=L[2]\n",
        "        i+=1\n",
        "        processing_thread = threading.Thread(target=process_request1,args=(iprompt,cprompt,steps))\n",
        "        processing_thread.start()\n",
        "    return jsonify(status1)\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/process1')\n",
        "def process1():\n",
        "  return render_template('result.html')\n",
        "\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return render_template('index.html',page1=page1)\n",
        "\n",
        "def add_numbers():\n",
        "    try:\n",
        "          !ngrok authtoken 2dEysJgwtjumyUuhWZxkmMwuCU6_2nEaorudYLXqoRzYHonjt\n",
        "          folder_path='/content/drive/MyDrive/data/instance'\n",
        "          files = os.listdir(folder_path)\n",
        "\n",
        "    # Iterate over the files and delete each one\n",
        "          for file in files:\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "              os.remove(file_path)\n",
        "              print(f\"File '{file_path}' deleted successfully.\")\n",
        "            except Exception as e:\n",
        "              print(f\"Error deleting file '{file_path}': {e}\")\n",
        "          INSTANCE_DIR = \"/content/drive/MyDrive/data/instance\"\n",
        "          iprompt = str(request.form.get('data1'))\n",
        "          print('done')\n",
        "          cprompt = str(request.form.get('data2'))\n",
        "          print('done')\n",
        "          steps = int(request.form.get('data3'))\n",
        "          print('done')\n",
        "          n=int(request.form.get('length_i'))\n",
        "          for i in range(n):\n",
        "            file0= request.files.getlist('file'+str(i))\n",
        "            for x in file0:\n",
        "              filename=secure_filename(x.filename)\n",
        "              x.save(os.path.join(INSTANCE_DIR,filename))\n",
        "          print('done')\n",
        "\n",
        "          cursor.execute(\"INSERT INTO `Prompts For Model Training` (`Instance Prompt`, `Class Prompt`, `Training Steps`) VALUES ( ?, ?, ? )\", (iprompt, cprompt, steps ))\n",
        "          conn.commit()\n",
        "          return [iprompt,cprompt,steps]\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred: {str(e)}\"\n",
        "        return render_template('error.html', message=error_message)\n",
        "\n",
        "\n",
        "@app.route('/add0', methods=['POST'])\n",
        "def two_page():\n",
        "  try :\n",
        "    !ngrok authtoken 2dEysJgwtjumyUuhWZxkmMwuCU6_2nEaorudYLXqoRzYHonjt\n",
        "    prompt = str(request.form['prompt'])\n",
        "    nprompt = str(request.form['nprompt'])\n",
        "    sample = int(request.form['sample'])\n",
        "    gs = float(request.form['gs'])\n",
        "    height = int(request.form['height'])\n",
        "    width = int(request.form['width'])\n",
        "    cursor.execute(\"INSERT INTO `Image Generation Prompts`('Prompt', `Negative Prompt`, `Sample Size`, `Guidance Scale`) VALUES ( ?, ?, ?, ? )\", (prompt, nprompt, sample, gs ))\n",
        "    conn.commit()\n",
        "    run2(prompt,nprompt,sample,gs,height,width)\n",
        "    image_filenames=[]\n",
        "    for x in range(1,sample+1):\n",
        "      image_filenames.append(\"generated_image_\"+str(x)+\".png\")\n",
        "    return render_template('final.html', image_filenames=image_filenames)\n",
        "  except Exception as e:\n",
        "        error_message = f\"An error occurred: {str(e)}\"\n",
        "        return render_template('error.html', message=error_message)\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/aboutus')\n",
        "def aboutus():\n",
        "    return render_template('aboutus.html')\n",
        "\n",
        "r(app)\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miMvLVHZ_d4n"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Replace 'your_database.db' with the actual database file path\n",
        "db_path = '/content/drive/MyDrive/Colab Notebooks/FYP/imagination.db'\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Execute a SELECT query to retrieve all rows from the 'users' table\n",
        "cursor.execute('SELECT * FROM `Prompts For Model Training`')\n",
        "\n",
        "# Fetch all rows and print the results\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "# # Close the connection\n",
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ5mjCzE3qym"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Replace 'your_database.db' with the actual database file path\n",
        "db_path = '/content/drive/MyDrive/Colab Notebooks/FYP/imagination.db'\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Execute a SELECT query to retrieve all rows from the 'users' table\n",
        "cursor.execute('SELECT * FROM `Image Generation Prompts`')\n",
        "\n",
        "# Fetch all rows and print the results\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "# # Close the connection\n",
        "# conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}